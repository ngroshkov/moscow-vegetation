{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dotenv\n",
    "%pip install pandas\n",
    "%pip install turfpy\n",
    "%pip install rasterio fiona rasterstats\n",
    "%pip install rasterio[s3]\n",
    "%pip install pystac-client sat-search \n",
    "%pip install pypalettes\n",
    "%pip install numpy\n",
    "%pip install pyfonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# City Municipal Districs\n",
    "with open(\"./mo.geojson\") as file:\n",
    "    districts = gpd.read_file(file)\n",
    "\n",
    "districts.set_crs(epsg=4326, inplace=True)\n",
    "districts.explore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "\n",
    "total_bounds = gpd.GeoDataFrame(index=[0], crs='epsg:4326', geometry=[shapely.box(*districts.total_bounds)])\n",
    "total_bounds.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "\n",
    "# Browse USGS STAC\n",
    "LandsatSTAC = Client.open(\"https://landsatlook.usgs.gov/stac-server\", headers=[])\n",
    "\n",
    "for collection in LandsatSTAC.get_collections():\n",
    "    print(f\"{collection.id}\\t\\t{collection.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "bbox = json.loads(total_bounds.to_json())['features'][0]['geometry']\n",
    "\n",
    "# STAC Search\n",
    "LandsatSearch = LandsatSTAC.search ( \n",
    "    intersects = bbox,\n",
    "    datetime = '2024-06-28/2024-06-28',\n",
    "    query =  ['eo:cloud_cover95'],\n",
    "    collections = [\"landsat-c2l2-sr\"] )\n",
    "\n",
    "Landsat_items = [i.to_dict() for i in LandsatSearch.get_items()]\n",
    "print(f\"{len(Landsat_items)} Landsat scenes fetched\")\n",
    "print(Landsat_items[0].keys())\n",
    "for item in Landsat_items:\n",
    "    print(item['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Landsat_item = Landsat_items[1]\n",
    "print(Landsat_item['assets'].keys())\n",
    "print(Landsat_item['assets']['red'].keys())\n",
    "print(Landsat_item['assets']['red'][\"href\"])\n",
    "print(Landsat_item['assets']['red'][\"alternate\"].keys())\n",
    "print(Landsat_item['assets']['red'][\"alternate\"]['s3'].keys())\n",
    "print(Landsat_item['assets']['red'][\"alternate\"]['s3']['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_href = Landsat_item['assets']['red']['href']\n",
    "nir_href = Landsat_item['assets']['nir08']['href']\n",
    "red_s3 = Landsat_item['assets']['red']['alternate']['s3']['href']\n",
    "nir_s3 = Landsat_item['assets']['nir08']['alternate']['s3']['href']\n",
    "print(red_href)    \n",
    "print(nir_href)\n",
    "print(red_s3)    \n",
    "print(nir_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tiff using STAC link  (not working)\n",
    "\n",
    "import requests\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "username = config['usgs_user']\n",
    "token = config['usgs_token']\n",
    "\n",
    "def download_file(session, url, filename):\n",
    "    r = session.get(url, stream=True)\n",
    "    if r.ok:\n",
    "        with open(filename, 'wb') as file:\n",
    "            # file.write(r.content)\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                file.write(chunk)\n",
    "        print(f\"File {filename} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download file {url}. Status code: {r.status_code}\")\n",
    "    return filename\n",
    "\n",
    "with requests.Session() as session:\n",
    "    data = {\n",
    "        'username': username, \n",
    "        'token': token\n",
    "    }\n",
    "    with session.post(\"https://m2m.cr.usgs.gov/api/api/json/stable/login-token\", json=data) as response:\n",
    "        api_token = response.json()['data']\n",
    "        print(api_token)\n",
    "        download_file(session, red_href, f\"{Landsat_item['id']}_B4.html\")\n",
    "        download_file(session, nir_href, f\"{Landsat_item['id']}_B5.TIF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Search\n",
    "\n",
    "import requests\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "username = config['usgs_user']\n",
    "token = config['usgs_token']\n",
    "\n",
    "# USGS M2M API key\n",
    "data = {\n",
    "    'username': username, \n",
    "    'token': token\n",
    "}\n",
    "with requests.post(\"https://m2m.cr.usgs.gov/api/api/json/stable/login-token\", json=data) as response:\n",
    "    print(response.status_code)\n",
    "    api_token = response.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "\n",
    "# Filters\n",
    "total_bounds = districts.total_bounds\n",
    "\n",
    "datasetName = \"landsat-c2l2-sr\"\n",
    "spatialFilter =  {\n",
    "    'filterType' : \"mbr\",\n",
    "    'lowerLeft' : { 'latitude' : total_bounds[1], 'longitude' : total_bounds[0] },\n",
    "    'upperRight' : { 'latitude' : total_bounds[3], 'longitude' : total_bounds[2] }\n",
    "}\n",
    "temporalFilter = {'start' : '2024-06-28', 'end' : '2024-06-28'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Datasets\n",
    "\n",
    "headers = {'X-Auth-Token': api_token}   \n",
    "\n",
    "payload = {\n",
    "    'datasetName' : 'Landsat 8-9 OLI/TIRS C2 L2',\n",
    "    'spatialFilter' : spatialFilter,\n",
    "    'temporalFilter' : temporalFilter,\n",
    "    \"publicOnly\": True\n",
    "}\n",
    "\n",
    "with (requests.post(\"https://m2m.cr.usgs.gov/api/api/json/stable/dataset-search\", json.dumps(payload), headers = headers)) as response:\n",
    "    print(response.status_code)\n",
    "    dataset = json.loads(response.text)\n",
    "\n",
    "print(json.dumps(dataset, indent=2))\n",
    "# for dataset in datasets:\n",
    "    # print(f\"{dataset['datasetAlias']} {dataset['collectionName']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'datasetName' : dataset['data'][0]['datasetAlias'], \n",
    "    'maxResults' : 10,\n",
    "    'startingNumber' : 0, \n",
    "    'sceneFilter' : {\n",
    "        'spatialFilter' : spatialFilter,\n",
    "        'acquisitionFilter' : temporalFilter,\n",
    "    }\n",
    "}\n",
    "\n",
    "with (requests.post(\"https://m2m.cr.usgs.gov/api/api/json/stable/scene-search\", json.dumps(data), headers = headers)) as response:\n",
    "    print(response.status_code)\n",
    "    scenes = json.loads(response.text)['data']['results']\n",
    "\n",
    "\n",
    "for scene in scenes:\n",
    "    print(f\"{scene['displayId']} {scene['temporalCoverage']} {scene['spatialCoverage']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialCoveragePolygons = []\n",
    "for scene in scenes:\n",
    "    # print(scene['spatialCoverage']['coordinates'][0])\n",
    "    coordinates = scene['spatialCoverage']['coordinates'][0]\n",
    "\n",
    "    spatialCoveragePolygons.append(shapely.geometry.Polygon(coordinates))\n",
    "\n",
    "spatialCoverage = gpd.GeoSeries(spatialCoveragePolygons)\n",
    "spatialCoverage.set_crs(epsg=4326, inplace=True)\n",
    "spatialCoverage.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download Scene\n",
    "scene = scenes[0]\n",
    "\n",
    "data = {\n",
    "    'datasetName' : dataset['data'][0]['datasetAlias'], \n",
    "    'entityIds' : scene['entityId'],\n",
    "     \"includeSecondaryFileGroups\": True,\n",
    "}\n",
    "\n",
    "with (requests.post(\"https://m2m.cr.usgs.gov/api/api/json/stable/download-options\", json.dumps(data), headers = headers)) as response:\n",
    "    print(response.status_code)\n",
    "    downloadOptions = json.loads(response.text)\n",
    "\n",
    "# print(json.dumps(downloadOptions, indent=2))\n",
    "for d in downloadOptions['data']:\n",
    "    print(f\"{d['id']} {d['displayId']} {d['productName']}, {d['productCode']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = next(p for p in downloadOptions['data'] if p['productCode'] == 'D694')\n",
    "print(json.dumps(product, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in product['secondaryDownloads']:\n",
    "    print(f\"{s['downloadName']} {s['displayId']} {s['productCode']}, {s['downloadName']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redBandProduct = next(x for x in product['secondaryDownloads'] if x['downloadName'] == 'SR_B4.TIF')\n",
    "nirBandProduct = next(x for x in product['secondaryDownloads'] if x['downloadName'] == 'SR_B5.TIF')\n",
    "\n",
    "products = [redBandProduct, nirBandProduct]\n",
    "print(json.dumps(redBandProduct, indent=2))\n",
    "print(json.dumps(nirBandProduct, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"downloads\": [\n",
    "        {\n",
    "            \"entityId\": redBandProduct['entityId'],\n",
    "            \"productId\": redBandProduct['id'],\n",
    "        },\n",
    "        {\n",
    "            \"entityId\": nirBandProduct['entityId'],\n",
    "            \"productId\": nirBandProduct['id'],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with (requests.post(\"https://m2m.cr.usgs.gov/api/api/json/stable/download-request\", json.dumps(data), headers = headers)) as response:\n",
    "    print(response.status_code)\n",
    "    downloadRequest = json.loads(response.text)\n",
    "    print(json.dumps(downloadRequest, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tiff \n",
    "def download_file(url, filename):\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.ok:\n",
    "        with open(filename, 'wb') as file:\n",
    "            # file.write(r.content)\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                file.write(chunk)\n",
    "        file.close()\n",
    "        print(f\"File {filename} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download file {url}. Status code: {r.status_code}\")\n",
    "    return filename\n",
    "\n",
    "# for ad in downloadRequest[\"data\"]['availableDownloads']:\n",
    "#     url = ad['url']\n",
    "#     entityId = ad['entityId']\n",
    "#     p = next(x for x in products if x['entityId'] == entityId)\n",
    "#     filename = p['displayId']\n",
    "#     download_file(url, filename)\n",
    "ad = downloadRequest[\"data\"]['availableDownloads'][1]\n",
    "url = ad['url']\n",
    "entityId = ad['entityId']\n",
    "p = next(x for x in products if x['entityId'] == entityId)\n",
    "filename = p['displayId']\n",
    "download_file(url, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# View Details \n",
    "with rasterio.open(f\"./{redBandProduct['displayId']}\") as tiff:\n",
    "    print(tiff)\n",
    "    print(tiff.meta)\n",
    "    print(tiff.profile)\n",
    "\n",
    "with rasterio.open(f\"./{nirBandProduct['displayId']}\") as tiff:\n",
    "    print(tiff)\n",
    "    print(tiff.meta)\n",
    "    print(tiff.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calc NDVI\n",
    "with rasterio.open(f\"./{redBandProduct['displayId']}\") as redBand, rasterio.open(f\"./{nirBandProduct['displayId']}\") as nirBand:\n",
    "    red = redBand.read(1)\n",
    "    nir = nirBand.read(1)\n",
    "\n",
    "    # https://www.usgs.gov/faqs/how-do-i-use-a-scale-factor-landsat-level-2-science-products\n",
    "    scale = 0.0000275\n",
    "    offset = -0.2\n",
    "\n",
    "    redValue = red * scale + offset\n",
    "    nirValue = nir * scale + offset\n",
    "\n",
    "    ndvi = (nirValue - redValue) / (nirValue + redValue)\n",
    "    ndvi = ndvi.clip(-1, 1)\n",
    "\n",
    "    redBand = tiff.profile\n",
    "    redBand.update(dtype=rasterio.float32, count=1, compress=\"lzw\")\n",
    "    ndvi_filename = f\"{product['displayId']}_SR_NDVI.TIF\"\n",
    "    # Save NDVI Raster\n",
    "    with rasterio.open(ndvi_filename, \"w\", **redBand) as dst:\n",
    "        dst.write(ndvi, 1)\n",
    "        print(f\"Raster data has been written to {ndvi_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.plot\n",
    "from pypalettes import add_cmap\n",
    "from pyfonts import load_google_font\n",
    "\n",
    "regular = load_google_font(\"Roboto\")\n",
    "bold = load_google_font(\"Roboto\", weight=\"bold\")\n",
    "\n",
    "cmap = add_cmap(\n",
    "    colors=[\n",
    "        \"#FFFFFF\",\n",
    "        \"#CE7E45\",\n",
    "        \"#DF923D\",\n",
    "        \"#F1B555\",\n",
    "        \"#FCD163\",\n",
    "        \"#99B718\",\n",
    "        \"#74A901\",\n",
    "        \"#66A000\",\n",
    "        \"#529400\",\n",
    "        \"#3E8601\",\n",
    "        \"#207401\",\n",
    "        \"#056201\",\n",
    "        \"#004C00\",\n",
    "        \"#023B01\",\n",
    "        \"#012E01\",\n",
    "        \"#011D01\",\n",
    "        \"#011301\",\n",
    "    ],\n",
    "    cmap_type=\"continuous\",\n",
    "    name=\"NDVI\",\n",
    ")\n",
    "\n",
    "districts.to_crs(epsg=32637, inplace=True)\n",
    "with rasterio.open(ndvi_filename) as ndvi:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.axis(\"off\")\n",
    "    img = rasterio.plot.show(ndvi, ax=ax, cmap=cmap, vmin=0, vmax=1)\n",
    "    im = img.get_images()[0]\n",
    "    fig.colorbar(im, ax=ax, shrink=0.5)\n",
    "    districts.dissolve().plot(ax=ax, edgecolor=\"white\", facecolor=\"none\", linewidth=1)\n",
    "    fig.text(x=0.5, y=0.79, s=\"Vegetation index (NDVI) in Moscow\", size=12, font=bold)\n",
    "    fig.text(x=0.5, y=0.76, s=\"In June 2024\", size=8, font=regular)\n",
    "    fig.text(x=0.2, y=0.20, s=\"Map: Nikolai Groshkov\\nSource: Landsat Collection 2 Level-2 image\\ncourtesy of the U.S. Geological Survey.\", \n",
    "        size=6, color=\"#909090\", font=regular\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "import geopandas as gpd\n",
    "\n",
    "# Calc and Join Zonal Stats\n",
    "districts_stats = districts.join(\n",
    "    gpd.GeoDataFrame(\n",
    "        zonal_stats(\n",
    "            vectors=districts['geometry'], \n",
    "            raster=ndvi_filename,\n",
    "            stats=['mean']\n",
    "        )\n",
    "    ),\n",
    "    how='left'\n",
    ").rename(columns={\"mean\": \"ndvi\"})\n",
    "\n",
    "districts_stats.to_file(\"mo.ndvi.stats.geojson\", driver=\"GeoJSON\")\n",
    "districts_stats = districts_stats.sort_values(by='ndvi').reset_index(drop=True)\n",
    "districts_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "bins=[0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "counts, bins = np.histogram(districts_stats[\"ndvi\"], bins=bins)\n",
    "colors = [cmap((val - min(bins)) / (max(bins) - min(bins))) for val in bins]\n",
    "\n",
    "_, _, patches = plt.hist(bins[:-1], bins, weights=counts,edgecolor='white')\n",
    "[patch.set_facecolor(colors[i]) for i, patch in enumerate(patches)]\n",
    "[plt.gca().spines[pos].set_visible(False) for pos in ['right', 'top', 'left']]\n",
    "plt.tick_params(axis='y', which='both', right=False, left=False, labelleft=False) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyfonts import load_google_font\n",
    "\n",
    "regular = load_google_font(\"Roboto\")\n",
    "bold = load_google_font(\"Roboto\", weight=\"bold\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "districts_stats.plot(ax=ax, column=\"ndvi\", cmap=cmap, edgecolor=\"#e6e6e6\", lw=0.3)\n",
    "\n",
    "# Barplot\n",
    "bins=[0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "counts, bins = np.histogram(districts_stats[\"ndvi\"], bins=bins)\n",
    "colors = [cmap((val - min(bins)) / (max(bins) - min(bins))) for val in bins]\n",
    "\n",
    "hist_ax = ax.inset_axes(bounds=[0.5, 0.1, 0.4, 0.15], zorder=-1)\n",
    "_, _, patches = hist_ax.hist(bins[:-1], bins, weights=counts,edgecolor='white')\n",
    "[patch.set_facecolor(colors[i]) for i, patch in enumerate(patches)]\n",
    "hist_ax.spines[[\"top\", \"left\", \"right\"]].set_visible(False)\n",
    "hist_ax.set_xticks(bins)\n",
    "hist_ax.set_yticks([])\n",
    "\n",
    "fig.text(x=0.2, y=0.89, s=\"Vegetation index (NDVI) in Moscow\", size=12, font=bold)\n",
    "fig.text(x=0.2, y=0.86, s=\"By district, in June 2024\", size=8, font=regular)\n",
    "fig.text(x=0.2, y=0.13, s=\"Map: Nikolai Groshkov Â· Source: Landsat Collection 2 Level-2 image courtesy of the U.S. Geological Survey.\", \n",
    "         size=6, color=\"#909090\", font=regular\n",
    "        )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
